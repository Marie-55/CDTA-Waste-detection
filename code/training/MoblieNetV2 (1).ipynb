{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN7l85GKhffw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7eiggnSNxUk"
      },
      "source": [
        "## 📂 Data Upload and Extraction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "587ce00c"
      },
      "source": [
        "First, let's upload the zip file containing your dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCLg_kdCN9K9"
      },
      "source": [
        "nb:you can find the dataset in this kaggle dataset\n",
        "https://www.kaggle.com/datasets/raniastudentlitim/cleaned-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "7cf80ee6",
        "outputId": "f3a12f51-c855-4e09-f45d-79eb611fb1e3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-67d116e3-4802-49fe-adb2-1d22fab5c903\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-67d116e3-4802-49fe-adb2-1d22fab5c903\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "  # Assuming the uploaded file is a zip file\n",
        "  zip_ref = zipfile.ZipFile(fn, 'r')\n",
        "  zip_ref.extractall('.')\n",
        "  zip_ref.close()\n",
        "\n",
        "  print(f\"Extracted contents of {fn}\")\n",
        "\n",
        "  # Assuming the cleaned dataset is named 'cleaned_dataset' and is a CSV file\n",
        "  # You might need to adjust this based on the actual file name and type\n",
        "  dataset_path = 'cleaned_dataset' # Update this if the filename is different\n",
        "\n",
        "  if os.path.exists(dataset_path):\n",
        "    print(f\"Found dataset at: {dataset_path}\")\n",
        "    # Now you can proceed to load and visualize the dataset\n",
        "  else:\n",
        "    print(f\"Could not find dataset at: {dataset_path}. Please check the filename inside the zip.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dceb2b64"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "extracted_files = os.listdir('.')\n",
        "print(\"Files extracted:\")\n",
        "for file in extracted_files:\n",
        "  print(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "src-qUgwOZVv"
      },
      "source": [
        "## 🧹 Dataset Preparation and Splitting\n",
        "\n",
        "\n",
        "- Scan all class subdirectories (e.g., `Plastic`, `Glass`, etc.) to build a DataFrame containing image file paths and their associated labels.\n",
        "- the dataset is split into training and validation sets using an 80/20 ratio, ensuring class balance via stratification.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPZtPrrG3Y22"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# --- Verify the path to your dataset ---\n",
        "# This path should point to the directory containing subdirectories for each class (e.g., 'Cardboard', 'Plastic', etc.)\n",
        "dataset_path = \"/content/cleaned_dataset\" # Assuming it's extracted to the root /content/ directory\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(f\"ERROR: The directory '{dataset_path}' does not exist.\")\n",
        "    print(\"Please make sure you have unzipped your data and the path is correct.\")\n",
        "else:\n",
        "    print(f\"Dataset found at: {dataset_path}\")\n",
        "\n",
        "    # --- Create a DataFrame of filepaths and labels ---\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate through each folder (which represents a class)\n",
        "    for class_folder in os.listdir(dataset_path):\n",
        "        class_path = os.path.join(dataset_path, class_folder)\n",
        "        if os.path.isdir(class_path):\n",
        "            for image_file in os.listdir(class_path):\n",
        "                filepaths.append(os.path.join(class_path, image_file))\n",
        "                labels.append(class_folder)\n",
        "\n",
        "    # Create the main DataFrame\n",
        "    df = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
        "\n",
        "    # --- Split into Training and Validation Sets ---\n",
        "    # We stratify by label to ensure both train and validation sets have a similar distribution of classes.\n",
        "    train_df, val_df = train_test_split(\n",
        "        df,\n",
        "        test_size=0.2,       # 20% for validation\n",
        "        random_state=42,\n",
        "        stratify=df['label']\n",
        "    )\n",
        "\n",
        "    print(\"\\nData successfully organized into training and validation DataFrames.\")\n",
        "    print(f\"Total images: {len(df)}\")\n",
        "    print(f\"Training samples: {len(train_df)}\")\n",
        "    print(f\"Validation samples: {len(val_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K1BYV343ZW7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# --- Corriger le chemin vers votre jeu de données ---\n",
        "# Puisque vos dossiers de catégories (Cardboard, Glass, etc.) sont directement dans /content/,\n",
        "# le chemin du jeu de données est simplement \"/content/\".\n",
        "dataset_path = \"/content/\"\n",
        "\n",
        "print(f\"Vérification du chemin : {dataset_path}\")\n",
        "\n",
        "# --- Créer un DataFrame des chemins de fichiers et des étiquettes ---\n",
        "filepaths = []\n",
        "labels = []\n",
        "\n",
        "# Liste des dossiers qui sont des catégories d'images (pour ignorer d'autres fichiers/dossiers)\n",
        "# D'après votre sortie, ce sont les catégories\n",
        "image_folders = [\n",
        "    'Textiles', 'Metals', 'Paper', 'Electronic Waste',\n",
        "    'Glass', 'Plastics', 'Cardboard', 'General Waste', 'Organic Waste'\n",
        "]\n",
        "\n",
        "# Parcourir chaque dossier de catégorie d'image\n",
        "for class_folder in image_folders:\n",
        "    class_path = os.path.join(dataset_path, class_folder)\n",
        "    if os.path.isdir(class_path):\n",
        "        for image_file in os.listdir(class_path):\n",
        "            filepaths.append(os.path.join(class_path, image_file))\n",
        "            labels.append(class_folder)\n",
        "    else:\n",
        "        print(f\"Attention : Le dossier de catégorie attendu n'a pas été trouvé : {class_path}\")\n",
        "\n",
        "\n",
        "# Créer le DataFrame principal\n",
        "df = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
        "\n",
        "# --- Diviser en ensembles d'entraînement et de validation ---\n",
        "# Nous stratifions par étiquette pour nous assurer que les ensembles d'entraînement et de validation ont une distribution de classes similaire.\n",
        "train_df, val_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,       # 20% pour la validation\n",
        "    random_state=42,\n",
        "    stratify=df['label']\n",
        ")\n",
        "\n",
        "print(\"\\nDonnées organisées avec succès en DataFrames d'entraînement et de validation.\")\n",
        "print(f\"Total des images trouvées : {len(df)}\")\n",
        "print(f\"Échantillons d'entraînement : {len(train_df)}\")\n",
        "print(f\"Échantillons de validation : {len(val_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOlqmxAKO20s"
      },
      "source": [
        "## 🧪 Step 2: Create Data Generators and Compute Class Weights\n",
        "\n",
        "In this step, we prepare the data for training and address class imbalance:\n",
        "\n",
        "- **Image Generators**: We use `ImageDataGenerator` to normalize pixel values by scaling them to the range [0, 1].\n",
        "  - The training generator shuffles data for better learning.\n",
        "  - The validation generator does not shuffle to ensure consistent evaluation.\n",
        "\n",
        "- **Class Weights Calculation**:\n",
        "  - We compute the class weights using `compute_class_weight` from `sklearn`, which balances the impact of underrepresented classes.\n",
        "  - The weights are mapped to each class index so they can be used during model training to compensate for class imbalance.\n",
        "\n",
        "This step ensures proper data feeding and handles any imbalance across waste categories to improve the model’s generalization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAR3jRIE-aew"
      },
      "outputs": [],
      "source": [
        "# --- Étape 2 : Créer les Générateurs de Données et Calculer les Poids des Classes ---\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# --- Paramètres de prétraitement ---\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Définir les générateurs (uniquement avec mise à l'échelle)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# --- Créer le générateur d'entraînement ---\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col=\"filepath\",\n",
        "    y_col=\"label\",\n",
        "    target_size=IMG_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# --- Créer le générateur de validation ---\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col=\"filepath\",\n",
        "    y_col=\"label\",\n",
        "    target_size=IMG_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False  # Pas besoin de mélanger les données de validation\n",
        ")\n",
        "\n",
        "# --- Calculer les Poids des Classes ---\n",
        "# Obtenir les indices des classes depuis le générateur\n",
        "class_indices = train_generator.class_indices\n",
        "\n",
        "# Inverser le dictionnaire pour mapper l'indice au nom de l'étiquette\n",
        "index_to_label = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "# Obtenir les étiquettes des classes depuis le dataframe d'entraînement\n",
        "y_labels = train_df['label']\n",
        "\n",
        "# Calculer les poids des classes\n",
        "class_weights_array = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_labels),\n",
        "    y=y_labels\n",
        ")\n",
        "label_to_weight = dict(zip(np.unique(y_labels), class_weights_array))\n",
        "\n",
        "# Construire le dictionnaire final class_weights en utilisant les indices de classe entiers\n",
        "class_weights_dict = {\n",
        "    class_indices[label]: weight for label, weight in label_to_weight.items()\n",
        "}\n",
        "\n",
        "print(\"\\n✅ Dictionnaire final class_weights_dict (indice → poids):\\n\")\n",
        "for idx, weight in sorted(class_weights_dict.items()):\n",
        "    label_name = index_to_label.get(idx, 'Inconnu')\n",
        "    print(f\"Classe {idx:2d} ({label_name:20s}): {weight:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXNN_U6mPBSD"
      },
      "source": [
        "## 🧠 Step 3: Build and Compile the MobileNetV2 Model\n",
        "\n",
        "In this step, we create a transfer learning model based on **MobileNetV2**, a lightweight CNN architecture pre-trained on ImageNet.\n",
        "\n",
        "- We **load MobileNetV2** without its top classification layer and freeze its convolutional base to preserve pre-trained features.\n",
        "- We add new layers:\n",
        "  - A `GlobalAveragePooling2D` layer to reduce the spatial dimensions.\n",
        "  - A fully connected `Dense` layer with ReLU activation.\n",
        "  - A final `Dense` layer with softmax activation for multiclass classification, using the correct number of classes inferred from the training generator.\n",
        "- The model is then compiled using the **Adam optimizer**, with **categorical crossentropy** loss (suitable for one-hot encoded labels), and **accuracy** as the performance metric.\n",
        "\n",
        "This approach leverages pre-trained visual features while allowing the model to adapt to our waste classification task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sa5cVFt_KHk"
      },
      "outputs": [],
      "source": [
        "# --- Step 3: Build and Compile the MobileNetV2 Model (Corrected) ---\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the MobileNetV2 base model, excluding its top classification layer\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=IMG_SIZE + (3,),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# Freeze the convolutional layers of the base model\n",
        "base_model.trainable = False\n",
        "\n",
        "# --- FIX IS HERE ---\n",
        "# Get the number of classes by finding the length of the class_indices dictionary\n",
        "num_classes = len(train_generator.class_indices)\n",
        "print(f\"Found {num_classes} classes.\")\n",
        "\n",
        "# --- Build the new model on top of the base model ---\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Combine the base model and our new custom layers into a single, final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# --- Compile the model ---\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Print a summary of the model's architecture\n",
        "print(\"\\n--- Model Summary ---\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVrFNdwbPLye"
      },
      "source": [
        "## 🏋️ Step 4: Train the Model\n",
        "\n",
        "In this step, we train the MobileNetV2-based classification model:\n",
        "\n",
        "- **Epochs**: The model is trained for 15 epochs.\n",
        "- **Callbacks**: We use `ModelCheckpoint` to save the model only when it achieves the best validation accuracy. This ensures we retain the most performant version.\n",
        "- **Class Weights**: We provide `class_weight` to the training process to handle class imbalance, allowing the model to give more importance to underrepresented categories.\n",
        "\n",
        "The training process will output accuracy and loss for both the training and validation sets across all epochs. The best-performing model is saved as `best_model.keras`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ75vB9d_fOR"
      },
      "outputs": [],
      "source": [
        "# --- Step 4: Train the Model ---\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the number of times the model will see the entire training dataset\n",
        "EPOCHS = 15\n",
        "\n",
        "# Define a callback to save the model's weights only when the validation accuracy improves.\n",
        "# This ensures we keep the best performing model.\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"best_model.keras\",        # Filepath to save the model\n",
        "    save_best_only=True,     # Only save if the model is the best so far\n",
        "    monitor=\"val_accuracy\",    # The metric to monitor for improvement\n",
        "    mode=\"max\"                 # We want to maximize this metric\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Model Training ---\")\n",
        "print(f\"The model will be trained for {EPOCHS} epochs.\")\n",
        "\n",
        "# Train the model using the .fit() method\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_generator,\n",
        "    class_weight=class_weights_dict, # This is crucial for handling the imbalanced data!\n",
        "    callbacks=[checkpoint_cb]        # Pass in our callback to save the best model\n",
        ")\n",
        "\n",
        "print(\"\\n--- Model Training Complete ---\")\n",
        "# The history object holds a record of the loss and accuracy values during training\n",
        "print(\"Best model has been saved to 'best_model.keras'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnalvOBPPVPL"
      },
      "source": [
        "## 📊 Step 5: Evaluate Model Performance and Visualize Results\n",
        "\n",
        "In this step, we assess the model’s performance and visualize its learning progress:\n",
        "\n",
        "### 1. Evaluation\n",
        "- We load the **best model** saved during training (`best_model.keras`) to ensure we evaluate the most optimal weights.\n",
        "- The model is evaluated on the validation set to report the **final loss and accuracy**.\n",
        "\n",
        "### 2. Visualization\n",
        "- We use the `history` object to plot:\n",
        "  - **Training vs. Validation Accuracy**\n",
        "  - **Training vs. Validation Loss**\n",
        "- These plots help us understand how well the model learned over time and if it overfit or underfit.\n",
        "\n",
        "Visual inspection of these graphs is crucial for diagnosing model behavior and identifying potential improvements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oojfzufBGi5"
      },
      "outputs": [],
      "source": [
        "# --- Step 5: Evaluate Performance and Visualize Results ---\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# --- 1. Evaluate the Model's Final Performance ---\n",
        "print(\"\\n--- Evaluating Final Model Performance ---\")\n",
        "\n",
        "# It's best practice to load the best saved model to ensure we evaluate the absolute best checkpoint.\n",
        "print(\"Loading the best model from 'best_model.keras'...\")\n",
        "best_model = tf.keras.models.load_model(\"best_model.keras\")\n",
        "\n",
        "# Evaluate the best model on the validation generator\n",
        "results = best_model.evaluate(val_generator)\n",
        "\n",
        "print(\"\\n--- Final Evaluation Metrics ---\")\n",
        "print(f\"Validation Loss: {results[0]:.4f}\")\n",
        "print(f\"Validation Accuracy: {results[1] * 100:.2f}%\") # Display as a percentage\n",
        "\n",
        "\n",
        "# --- 2. Visualize Training History ---\n",
        "print(\"\\n--- Plotting Training History ---\")\n",
        "\n",
        "# Extracting metrics from the 'history' object\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Get the number of epochs the training actually ran for\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "# Create a figure to plot on\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Plot Training & Validation Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "# Plot Training & Validation Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Display the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1DPFV0sPjpx"
      },
      "source": [
        "## 📈 Interpretation of Results\n",
        "\n",
        "### ✅ Final Evaluation Metrics:\n",
        "- **Validation Accuracy**: **96.83%**\n",
        "- **Validation Loss**: **0.1536**\n",
        "\n",
        "These results indicate that the trained model generalizes **very well** to unseen validation data. Achieving nearly 97% accuracy means the model has successfully learned to distinguish between the different waste categories with high precision.\n",
        "\n",
        "The low validation loss further confirms that the predictions are confident and well-calibrated, not just correct by chance.\n",
        "\n",
        "---\n",
        "\n",
        "### 📉 Training History Analysis:\n",
        "\n",
        "- The **training and validation accuracy curves** show consistent improvement and closely follow each other, which suggests that:\n",
        "  - The model is **not overfitting** (no divergence between training and validation performance).\n",
        "  - The training was **stable**, and the model benefited from the class weights and preprocessing.\n",
        "  \n",
        "- The **loss curves** steadily decrease, and the validation loss does not spike, confirming that:\n",
        "  - The model is not underfitting.\n",
        "  - The optimizer was able to effectively minimize the error across epochs.\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 Inference:\n",
        "- The combination of a well-prepared dataset, class weighting, and transfer learning from MobileNetV2 led to a **high-performing image classifier**.\n",
        "- This model is now well-suited for deployment or further fine-tuning (e.g., unfreezing the base layers for even better results).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOH11a3KVBkD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c19517de"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('best_model.keras')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}